"""
Vulnerability Scanner Module for CodeSentinel - Phase 3
Integrates Semgrep and Bandit for comprehensive security analysis
"""

import json
import logging
import subprocess
import shutil
import tempfile
import os
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
import sys

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.github_analyzer import FileInfo, Manifest

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


@dataclass
class VulnerabilityFinding:
    """Data class for vulnerability findings"""
    tool: str
    rule_id: str
    severity: str
    message: str
    line_start: int
    line_end: int
    confidence: str
    file_path: str
    cwe: Optional[str] = None
    fix_suggestion: Optional[str] = None
    references: Optional[List[str]] = None
    test_name: Optional[str] = None
    more_info: Optional[str] = None


class SecurityToolManager:
    """Manages installation and verification of security tools"""
    
    def __init__(self):
        self.tools_status = {}
        logger.info("Initializing Security Tool Manager")
    
    def check_and_install_tools(self) -> Dict[str, bool]:
        """Check if tools are installed, install if missing"""
        tools = {
            'semgrep': self._check_semgrep,
            'bandit': self._check_bandit,
            'git': self._check_git
        }
        
        for tool, checker in tools.items():
            logger.info(f"Checking {tool} availability...")
            if not checker():
                logger.info(f"Installing {tool}...")
                success = self._install_tool(tool)
                self.tools_status[tool] = success
                if success:
                    logger.info(f"✅ {tool} installed successfully")
                else:
                    logger.error(f"❌ Failed to install {tool}")
            else:
                logger.info(f"✅ {tool} already available")
                self.tools_status[tool] = True
                
        return self.tools_status
    
    def _check_semgrep(self) -> bool:
        """Check if Semgrep is installed and accessible"""
        return shutil.which('semgrep') is not None
    
    def _check_bandit(self) -> bool:
        """Check if Bandit is installed"""
        try:
            import bandit
            return True
        except ImportError:
            return shutil.which('bandit') is not None
    
    def _check_git(self) -> bool:
        """Check if Git is installed"""
        return shutil.which('git') is not None
    
    def _install_tool(self, tool: str) -> bool:
        """Install security tool using pip"""
        try:
            if tool == 'semgrep':
                subprocess.run(['pip', 'install', 'semgrep'], check=True, capture_output=True)
            elif tool == 'bandit':
                subprocess.run(['pip', 'install', 'bandit[toml]'], check=True, capture_output=True)
            elif tool == 'git':
                logger.error("Git must be installed manually. Please install Git and try again.")
                return False
            return True
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to install {tool}: {e}")
            return False


class RepositoryManager:
    """Handles repository cloning and cleanup"""
    
    def __init__(self, temp_dir: Optional[str] = None):
        self.temp_dir = temp_dir or tempfile.mkdtemp(prefix='codesentinel_')
        self.cleanup_paths = []
        logger.info(f"Repository manager initialized with temp dir: {self.temp_dir}")
    
    def clone_repository(self, repo_url: str, commit_sha: Optional[str] = None) -> Path:
        """Clone repository to temporary directory"""
        repo_name = self._extract_repo_name(repo_url)
        clone_path = Path(self.temp_dir) / repo_name
        
        try:
            logger.info(f"Cloning repository: {repo_url}")
            
            # Clone with depth=1 for speed unless we need specific commit
            if commit_sha:
                cmd = ['git', 'clone', repo_url, str(clone_path)]
                subprocess.run(cmd, check=True, capture_output=True, text=True)
                # Checkout specific commit
                subprocess.run(['git', 'checkout', commit_sha], 
                             cwd=clone_path, check=True, capture_output=True, text=True)
                logger.info(f"Checked out commit: {commit_sha}")
            else:
                cmd = ['git', 'clone', '--depth=1', repo_url, str(clone_path)]
                subprocess.run(cmd, check=True, capture_output=True, text=True)
            
            self.cleanup_paths.append(clone_path)
            logger.info(f"Repository cloned to: {clone_path}")
            return clone_path
            
        except subprocess.CalledProcessError as e:
            logger.error(f"Failed to clone repository: {e}")
            if hasattr(e, 'stderr') and e.stderr:
                logger.error(f"Git error: {e.stderr}")
            raise
    
    def _extract_repo_name(self, repo_url: str) -> str:
        """Extract repository name from URL"""
        # Handle both https://github.com/user/repo and git@github.com:user/repo formats
        if repo_url.endswith('.git'):
            repo_url = repo_url[:-4]
        
        if '/' in repo_url:
            return repo_url.split('/')[-1]
        else:
            return repo_url
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """Clean up cloned repositories"""
        logger.info("Cleaning up temporary repositories...")
        for path in self.cleanup_paths:
            if path.exists():
                shutil.rmtree(path, ignore_errors=True)
                logger.debug(f"Removed: {path}")
        
        if Path(self.temp_dir).exists():
            shutil.rmtree(self.temp_dir, ignore_errors=True)
            logger.debug(f"Removed temp dir: {self.temp_dir}")


class VulnerabilityScanner:
    """Main scanning orchestrator"""
    
    def __init__(self, config: Dict):
        self.config = config.get('vulnerability_scanning', {})
        self.tool_manager = SecurityToolManager()
        logger.info("Vulnerability scanner initialized")
        
    def scan_repository(self, repo_path: Path, manifest: Manifest) -> Dict:
        """Run comprehensive vulnerability scans"""
        
        logger.info("Starting vulnerability scanning...")
        
        # Ensure tools are available
        tool_status = self.tool_manager.check_and_install_tools()
        if not all(tool_status.values()):
            missing = [tool for tool, status in tool_status.items() if not status]
            raise RuntimeError(f"Failed to install required tools: {missing}")
        
        results = {
            'semgrep_findings': {},
            'bandit_findings': {},
            'scan_metadata': {
                'scan_timestamp': datetime.now(timezone.utc).isoformat(),
                'tools_used': list(tool_status.keys()),
                'repo_path': str(repo_path),
                'total_files_scanned': len(manifest.files)
            }
        }
        
        # Run Semgrep scan
        if self.config.get('semgrep', {}).get('enabled', True):
            try:
                logger.info("Running Semgrep scan...")
                results['semgrep_findings'] = self._run_semgrep(repo_path)
                finding_count = sum(len(findings) for findings in results['semgrep_findings'].values())
                logger.info(f"Semgrep found {finding_count} issues across {len(results['semgrep_findings'])} files")
            except Exception as e:
                logger.error(f"Semgrep scan failed: {e}")
                results['semgrep_findings'] = {}
        
        # Run Bandit scan  
        if self.config.get('bandit', {}).get('enabled', True):
            try:
                logger.info("Running Bandit scan...")
                results['bandit_findings'] = self._run_bandit(repo_path)
                finding_count = sum(len(findings) for findings in results['bandit_findings'].values())
                logger.info(f"Bandit found {finding_count} issues across {len(results['bandit_findings'])} files")
            except Exception as e:
                logger.error(f"Bandit scan failed: {e}")
                results['bandit_findings'] = {}
        
        return results
    
    def _run_semgrep(self, repo_path: Path) -> Dict:
        """Execute Semgrep scan and parse results"""
        semgrep_config = self.config.get('semgrep', {})
        
        cmd = [
            'semgrep',
            '--json',
            '--config=auto',  # Use Semgrep's curated rules
            '--timeout', str(semgrep_config.get('timeout', 120)),
            '--quiet',
            '--no-git-ignore',  # Scan all files, not just git-tracked ones
            str(repo_path)
        ]
        
        # Add exclusions if configured
        exclude_patterns = semgrep_config.get('exclude_patterns', ['tests/', '*.min.js', 'node_modules/'])
        for pattern in exclude_patterns:
            cmd.extend(['--exclude', pattern])
        
        try:
            logger.debug(f"Running Semgrep command: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            if result.returncode in [0, 1, 2]:  # 0 = no findings, 1 = findings found, 2 = errors but continued
                if result.stdout.strip():
                    scan_results = json.loads(result.stdout)
                    return self._normalize_semgrep_results(scan_results, repo_path)
                else:
                    logger.info("Semgrep completed with no output")
                    return {}
            else:
                logger.error(f"Semgrep failed with exit code {result.returncode}")
                if result.stderr:
                    logger.error(f"Semgrep stderr: {result.stderr}")
                return {}
                
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Semgrep JSON output: {e}")
            logger.debug(f"Semgrep stdout: {result.stdout}")
            return {}
        except Exception as e:
            logger.error(f"Unexpected error running Semgrep: {e}")
            return {}
    
    def _normalize_semgrep_results(self, scan_results: Dict, repo_path: Path) -> Dict:
        """Normalize Semgrep results to our format"""
        findings_by_file = {}
        
        results = scan_results.get('results', [])
        for result in results:
            file_path = result.get('path', '')
            
            # Convert absolute path to relative path
            try:
                relative_path = str(Path(file_path).relative_to(repo_path))
            except ValueError:
                # If path is already relative or can't be made relative
                relative_path = file_path
            
            if relative_path not in findings_by_file:
                findings_by_file[relative_path] = []
            
            finding = {
                'check_id': result.get('check_id', 'unknown'),
                'message': result.get('extra', {}).get('message', 'No description'),
                'severity': result.get('extra', {}).get('severity', 'INFO'),
                'line_start': result.get('start', {}).get('line', 1),
                'line_end': result.get('end', {}).get('line', 1),
                'confidence': 'high',  # Semgrep generally has high confidence
                'metadata': result.get('extra', {}).get('metadata', {}),
                'fix': result.get('extra', {}).get('fix'),
                'references': result.get('extra', {}).get('references', [])
            }
            findings_by_file[relative_path].append(finding)
        
        return findings_by_file
    
    def _run_bandit(self, repo_path: Path) -> Dict:
        """Execute Bandit scan and parse results"""
        bandit_config = self.config.get('bandit', {})
        
        # Use Bandit CLI for broader compatibility
        cmd = [
            'bandit',
            '-r', str(repo_path),
            '-f', 'json',
            '-ll',  # Report low severity and above
            '-i',   # Report low confidence and above
        ]
        
        # Add exclusions if configured
        if bandit_config.get('exclude_tests', True):
            cmd.extend(['-x', '*test*,*/tests/*,*/test_*'])
        
        try:
            logger.debug(f"Running Bandit command: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)
            
            # Bandit returns 1 when issues are found, which is normal
            if result.returncode in [0, 1]:
                if result.stdout.strip():
                    scan_results = json.loads(result.stdout)
                    return self._normalize_bandit_results(scan_results, repo_path)
                else:
                    logger.info("Bandit completed with no output")
                    return {}
            else:
                logger.error(f"Bandit failed with exit code {result.returncode}")
                if result.stderr:
                    logger.error(f"Bandit stderr: {result.stderr}")
                return {}
                
        except json.JSONDecodeError as e:
            logger.error(f"Failed to parse Bandit JSON output: {e}")
            logger.debug(f"Bandit stdout: {result.stdout}")
            return {}
        except Exception as e:
            logger.error(f"Unexpected error running Bandit: {e}")
            return {}
    
    def _normalize_bandit_results(self, scan_results: Dict, repo_path: Path) -> Dict:
        """Normalize Bandit results to our format"""
        findings_by_file = {}
        
        results = scan_results.get('results', [])
        for result in results:
            file_path = result.get('filename', '')
            
            # Convert absolute path to relative path
            try:
                relative_path = str(Path(file_path).relative_to(repo_path))
            except ValueError:
                # If path is already relative or can't be made relative
                relative_path = file_path
            
            if relative_path not in findings_by_file:
                findings_by_file[relative_path] = []
            
            finding = {
                'rule_id': result.get('test_id', 'unknown'),
                'severity': result.get('issue_severity', 'LOW'),
                'confidence': result.get('issue_confidence', 'LOW'),
                'description': result.get('issue_text', 'No description'),
                'line_number': result.get('line_number', 1),
                'test_name': result.get('test_name', 'unknown'),
                'more_info': result.get('more_info', ''),
                'code': result.get('code', '')
            }
            findings_by_file[relative_path].append(finding)
        
        return findings_by_file


class ManifestEnhancer:
    """Updates manifest with vulnerability data"""
    
    def __init__(self):
        logger.info("Manifest enhancer initialized")
    
    def update_manifest_with_vulnerabilities(self, 
                                           manifest: Manifest, 
                                           scan_results: Dict) -> Manifest:
        """Enhance existing manifest with vulnerability findings"""
        
        logger.info("Updating manifest with vulnerability data...")
        
        # Create file path to findings mapping
        semgrep_findings = scan_results.get('semgrep_findings', {})
        bandit_findings = scan_results.get('bandit_findings', {})
        
        total_vulnerabilities = 0
        files_with_vulns = 0
        
        for file_info in manifest.files:
            file_path = file_info.path
            vulnerabilities = []
            
            # Add Semgrep findings
            if file_path in semgrep_findings:
                for finding in semgrep_findings[file_path]:
                    vuln = {
                        'tool': 'semgrep',
                        'rule_id': finding['check_id'],
                        'severity': self._normalize_severity(finding['severity']),
                        'message': finding['message'],
                        'line_start': finding['line_start'],
                        'line_end': finding['line_end'],
                        'confidence': finding['confidence'],
                        'cwe': finding['metadata'].get('cwe'),
                        'fix_suggestion': finding.get('fix'),
                        'references': finding.get('references', [])
                    }
                    vulnerabilities.append(vuln)
            
            # Add Bandit findings  
            if file_path in bandit_findings:
                for finding in bandit_findings[file_path]:
                    vuln = {
                        'tool': 'bandit',
                        'rule_id': finding['rule_id'],
                        'severity': self._normalize_severity(finding['severity']),
                        'message': finding['description'],
                        'line_start': finding['line_number'],
                        'line_end': finding['line_number'],
                        'confidence': finding['confidence'].lower(),
                        'test_name': finding['test_name'],
                        'more_info': finding['more_info'],
                        'code_snippet': finding.get('code', '')[:200]  # Limit code snippet length
                    }
                    vulnerabilities.append(vuln)
            
            # Update file info
            file_info.vulnerabilities = vulnerabilities
            
            # Calculate vulnerability metrics
            if vulnerabilities:
                files_with_vulns += 1
                total_vulnerabilities += len(vulnerabilities)
            
            # Update total vulnerabilities count (for backward compatibility)
            file_info.total_vulnerabilities = len(vulnerabilities)
            
            # Calculate vulnerability score for risk assessment
            file_info.vulnerability_score = self._calculate_vuln_score(vulnerabilities)
        
        logger.info(f"✅ Updated manifest: {total_vulnerabilities} vulnerabilities found across {files_with_vulns} files")
        
        return manifest
    
    def _normalize_severity(self, severity: str) -> str:
        """Normalize severity levels across tools"""
        severity_map = {
            # Semgrep levels
            'ERROR': 'critical',
            'WARNING': 'high', 
            'INFO': 'medium',
            
            # Bandit levels
            'HIGH': 'critical',
            'MEDIUM': 'high',
            'LOW': 'medium'
        }
        normalized = severity_map.get(severity.upper(), 'low')
        return normalized
    
    def _calculate_vuln_score(self, vulnerabilities: List[Dict]) -> float:
        """Calculate weighted vulnerability score (0.0-1.0)"""
        if not vulnerabilities:
            return 0.0
        
        severity_weights = {
            'critical': 1.0,
            'high': 0.7,
            'medium': 0.4,
            'low': 0.1
        }
        
        total_score = sum(severity_weights.get(v.get('severity', 'low'), 0.1) 
                         for v in vulnerabilities)
        
        # Normalize to 0.0-1.0 scale (assuming max 10 critical issues per file)
        normalized_score = min(total_score / 10.0, 1.0)
        return round(normalized_score, 3)


def run_vulnerability_analysis(repo_url: str, manifest: Manifest, config: Dict) -> Tuple[Manifest, Dict]:
    """
    Main entry point for vulnerability analysis
    
    Args:
        repo_url: Repository URL to clone and scan
        manifest: Existing manifest to enhance
        config: Configuration dictionary
        
    Returns:
        Tuple of (enhanced_manifest, scan_results)
    """
    
    logger.info(f"Starting vulnerability analysis for: {repo_url}")
    
    try:
        with RepositoryManager() as repo_mgr:
            # Extract commit SHA from manifest if available
            commit_sha = getattr(manifest.repository, 'commit_sha', None)
            
            # Clone repository
            repo_path = repo_mgr.clone_repository(repo_url, commit_sha)
            
            # Initialize scanner and run scans
            scanner = VulnerabilityScanner(config)
            scan_results = scanner.scan_repository(repo_path, manifest)
            
            # Update manifest with findings
            enhancer = ManifestEnhancer()
            enhanced_manifest = enhancer.update_manifest_with_vulnerabilities(
                manifest, scan_results
            )
            
            logger.info("Vulnerability analysis completed successfully")
            return enhanced_manifest, scan_results
            
    except Exception as e:
        logger.error(f"Vulnerability analysis failed: {e}")
        raise


if __name__ == "__main__":
    # Test the scanner functionality
    import yaml
    
    # Load config
    with open('config.yaml', 'r') as f:
        config = yaml.safe_load(f)
    
    # Test tool installation
    tool_mgr = SecurityToolManager()
    status = tool_mgr.check_and_install_tools()
    print(f"Tool status: {status}")
